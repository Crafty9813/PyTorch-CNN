{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.6753, -2.6988, -1.6884, -1.4170, -2.5398, -2.6172, -3.0376, -2.8240,\n",
      "         -2.1923, -2.7224]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jli28/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "class Net (nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super (Net, self).__init__()\n",
    "\n",
    "        #2d convolution layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "        # dropout layers for less co-adaptation\n",
    "\n",
    "        self.dropout1 = nn.Dropout2d(0.2) #randomly set 25% of neurons to 0/null\n",
    "        self.dropout2 = nn.Dropout2d(0.5) #randomly set 50% of neurons to 0/null\n",
    "\n",
    "        self.fc1 = nn.Linear(9216, 128) # hidden layer\n",
    "        self.fc2 = nn.Linear(128, 10) # output layer\n",
    "\n",
    "\n",
    "    def forward (self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = func.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = func.relu(x)\n",
    "\n",
    "        x = func.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = func.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        output = func.log_softmax(x, dim = 1)\n",
    "        return output\n",
    "\n",
    "random_data = torch.rand((1, 1, 28, 28))\n",
    "neuralNetwork = Net()\n",
    "result = neuralNetwork(random_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(1)\n",
    "vector = torch.tensor([1, 1])\n",
    "matrix = torch.tensor([[1, 1], [2, 2]]) #basically a 2d arr\n",
    "\n",
    "random_tensor = torch.rand(3, 4)\n",
    "\n",
    "ones = torch.ones(3, 3)\n",
    "\n",
    "thing = torch.arange(1, 11, 1)\n",
    "\n",
    "newThing = torch.zeros_like(thing)\n",
    "newThing\n",
    "matrix.ndim\n",
    "#random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
